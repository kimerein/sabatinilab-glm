{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dfrel_to_ho_set():\n",
    "#     return\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os \n",
    "import glob\n",
    "dir_path = os.path.dirname(os.path.realpath('.'))\n",
    "nb_names = glob.glob(str((Path(dir_path) / 'production' / '02-*.ipynb').resolve()))\n",
    "print(dir_path)\n",
    "print(nb_names)\n",
    "assert len(nb_names) == 1\n",
    "nb_full_path = nb_names[0]\n",
    "nb_name = nb_full_path.split('/')[-1]\n",
    "nb_full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%javascript\n",
    "## IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%javascript\n",
    "## IPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# nb_full_path = os.path.join(os.getcwd(), nb_name)\n",
    "# nb_full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# From stack overflow\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from logging.config import _RootLoggerConfiguration\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def create_folder_if_not_exists(dir):\n",
    "    dir = str(Path(dir).resolve())\n",
    "    constructed_dir = '/'\n",
    "    made = False\n",
    "    for fold in dir.split('/'):\n",
    "        if len(fold) == 0:\n",
    "            continue\n",
    "        constructed_dir += fold + '/'\n",
    "        if os.path.isdir(constructed_dir):\n",
    "            # print(f'Directory already exists:', constructed_dir)\n",
    "            pass\n",
    "        else:\n",
    "            # print(f'Creating directory:', constructed_dir)\n",
    "            os.mkdir(constructed_dir)\n",
    "            made = True\n",
    "    if made:\n",
    "        print(f'Created directory:', constructed_dir)\n",
    "    return\n",
    "\n",
    "# create_folder_if_not_exists((Path.home() / 'Desktop/nada/folder2').resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1355_1356_1357_1358_1374_1376_1448_1449_1450_1451'] 0 1355_1356_1357_1358_1374_1376_1448_1449_1450_1451\n",
      "dfrel_basis (1900992, 757)\n",
      "FINAL_1355_1356_1357_1358_1374_1376_1448_1449_1450_1451.csv\n",
      "- ['gACH', 'gACH', 'gACH']\n",
      "dfr.shape (1900992, 688)\n",
      "> Included file_nums for y_col gACH: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52]\n",
      "X_setup.columns: Index(['rDA_-20', 'rDA_-19', 'rDA_-18', 'rDA_-17', 'rDA_-16', 'rDA_-15',\n",
      "       'rDA_-14', 'rDA_-13', 'rDA_-12', 'rDA_-11', 'rDA_-10', 'rDA_-9',\n",
      "       'rDA_-8', 'rDA_-7', 'rDA_-6', 'rDA_-5', 'rDA_-4', 'rDA_-3', 'rDA_-2',\n",
      "       'rDA_-1', 'rDA_0', 'rDA_1', 'rDA_2', 'rDA_3', 'rDA_4', 'rDA_5', 'rDA_6',\n",
      "       'rDA_7', 'rDA_8', 'rDA_9', 'rDA_10', 'rDA_11', 'rDA_12', 'rDA_13',\n",
      "       'rDA_14', 'rDA_15', 'rDA_16', 'rDA_17', 'rDA_18', 'rDA_19', 'rDA_20'],\n",
      "      dtype='object')\n",
      "Variable Sizes:\n",
      "                   dfrel_basis: 10.9 GiB\n",
      "                     signal_df: 10.7 GiB\n",
      "                      dfrel_ft:  9.7 GiB\n",
      "                         dfrel:  9.7 GiB\n",
      "                    dfrel_witi:  9.7 GiB\n",
      "                dfrel_ft_setup:  7.9 GiB\n",
      "                   dfrel_setup:  7.9 GiB\n",
      "              dfrel_setup_witi:  7.9 GiB\n",
      "                   dfrel_noiti:  7.1 GiB\n",
      "             dfrel_setup_noiti:  5.9 GiB\n",
      "              dfrel_ft_holdout:  1.8 GiB\n",
      "                 dfrel_holdout:  1.8 GiB\n",
      "            dfrel_holdout_witi:  1.8 GiB\n",
      "           dfrel_holdout_noiti:  1.3 GiB\n",
      "                        X_witi: 603.7 MiB\n",
      "                  X_setup_witi: 492.2 MiB\n",
      "                       X_noiti: 443.1 MiB\n",
      "                 X_setup_noiti: 363.0 MiB\n",
      "                  dfrel_resids: 346.3 MiB\n",
      "            dfrel_resids_setup: 282.3 MiB\n",
      "                X_holdout_witi: 111.5 MiB\n",
      "               X_holdout_noiti: 80.1 MiB\n",
      "          dfrel_resids_holdout: 63.9 MiB\n",
      "                         srs_a: 23.6 MiB\n",
      "                         srs_b: 23.6 MiB\n",
      "                        y_witi: 23.6 MiB\n",
      "                  y_setup_witi: 19.2 MiB\n",
      "                       y_noiti: 17.3 MiB\n",
      "                 y_setup_noiti: 14.2 MiB\n",
      "                       holdout: 10.9 MiB\n",
      "kwargs {}\n",
      "PCA fit in 1.7193577289581299 seconds\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GLM' object has no attribute 'fit_intercept'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 86>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, size \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(((name, sys\u001b[38;5;241m.\u001b[39mgetsizeof(value)) \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlocals\u001b[39m()\u001b[38;5;241m.\u001b[39mitems()),\n\u001b[1;32m    684\u001b[0m                          key\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m-\u001b[39mx[\u001b[38;5;241m1\u001b[39m])[:\u001b[38;5;241m30\u001b[39m]:\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:>30}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{:>8}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, sizeof_fmt(size)))\n\u001b[0;32m--> 687\u001b[0m best_score, best_score_std, best_params, best_model, cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msglm_cv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimple_cv_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_setup_noiti\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_setup_noiti\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkfold_cv_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglm_kwarg_lst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNormal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m                                                                                            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscore_method\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28meval\u001b[39m\u001b[38;5;241m.\u001b[39mprint_best_model_info(X_setup_noiti, best_score, best_params, best_model, start)\n\u001b[1;32m    697\u001b[0m glm, holdout_score, holdout_neg_mse_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_fit_holdout_score(X_setup_noiti, y_setup_noiti, X_holdout_noiti, y_holdout_noiti, best_params)\n",
      "File \u001b[0;32m~/github-repos/sabatinilab-glm/sglm/sglm/models/sglm_cv.py:47\u001b[0m, in \u001b[0;36msimple_cv_fit\u001b[0;34m(X, y, cv_idx, glm_kwarg_lst, model_type, verbose, score_method)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03mFit the desired model using the list of keyword arguments provided in\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03mglm_kwarg_lst, identify the best model, and return the associated\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m         Best Score Value, Best Score Standard Deviation, Best Params, Best Model\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Step 4: Fit GLM models for all possible sets of values\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcv_glm_mult_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m                                \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mcv_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mglm_kwarg_lst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mscore_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscore_method\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;66;43;03m# [tuple([glm_kwarg[_] for _ in []]) for glm_kwarg in glm_kwarg_lst]\u001b[39;49;00m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m best_score \u001b[38;5;241m=\u001b[39m cv_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     57\u001b[0m best_score_std \u001b[38;5;241m=\u001b[39m cv_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_score_std\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/github-repos/sabatinilab-glm/sglm/sglm/models/sglm_cv.py:295\u001b[0m, in \u001b[0;36mcv_glm_mult_params\u001b[0;34m(X, y, cv_idx, model_name, glm_kwarg_lst, verbose, score_method)\u001b[0m\n\u001b[1;32m    292\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    294\u001b[0m pca_glm \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39msglm\u001b[38;5;241m.\u001b[39mGLM(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPCA Normal\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNormal\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGaussian\u001b[39m\u001b[38;5;124m'\u001b[39m} \u001b[38;5;28;01melse\u001b[39;00m models\u001b[38;5;241m.\u001b[39msglm\u001b[38;5;241m.\u001b[39mGLM(model_name)\n\u001b[0;32m--> 295\u001b[0m \u001b[43mpca_glm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpca_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m> PCA GLM Built in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    298\u001b[0m beta0_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/github-repos/sabatinilab-glm/sglm/sglm/models/sglm.py:220\u001b[0m, in \u001b[0;36mGLM.pca_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    217\u001b[0m X_trans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpca\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    219\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 220\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_trans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m> PCA-based Model fit in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    223\u001b[0m W \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpca\u001b[38;5;241m.\u001b[39mcomponents_\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m~/github-repos/sabatinilab-glm/sglm/sglm/models/sglm.py:268\u001b[0m, in \u001b[0;36mGLM.fit\u001b[0;34m(self, X, y, *args)\u001b[0m\n\u001b[1;32m    265\u001b[0m y_ \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(y) \u001b[38;5;241m==\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(y) \u001b[38;5;241m==\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries \u001b[38;5;28;01melse\u001b[39;00m y\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(X_) \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(y_) \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray\n\u001b[0;32m--> 268\u001b[0m X_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([X_, np\u001b[38;5;241m.\u001b[39mones((X_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m))], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mconcatenate([X_], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# self.full_betas_ = np.linalg.pinv(X_.T @ X_) @ X_.T @ y_\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfull_betas_, _, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrank_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingular_  \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mlstsq(X_, y_, rcond\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GLM' object has no attribute 'fit_intercept'"
     ]
    }
   ],
   "source": [
    "\n",
    "from sglm.models import sglm_cv\n",
    "import itertools\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sglm.features import gen_signal_df as gsd\n",
    "from sglm.features import build_features as bf\n",
    "from sglm.features import setup_model_fit as smf\n",
    "from sglm.models import sglm_cv\n",
    "from sglm import models\n",
    "from sglm.visualization import visualize\n",
    "from sglm.models import train_model\n",
    "from sglm.models import eval\n",
    "from sglm import features\n",
    "\n",
    "neg_order = -20\n",
    "pos_order = 20\n",
    "\n",
    "fix_training = True\n",
    "# fix_training = False\n",
    "ft_str = '-ft' if fix_training else ''\n",
    "\n",
    "# multifile_fit = 'single' #False\n",
    "# multifile_fit = 'all' #True\n",
    "# multifile_fit = 'by_mouse'\n",
    "# multifile_fit_list = ['all']\n",
    "# multifile_fit_list = ['by_mouse']\n",
    "multifile_fit_list = ['all']\n",
    "# multifile_fit_list = ['by_mouse', 'all']\n",
    "# multifile_fit_list = ['all']\n",
    "# multifile_fit_list = ['single']\n",
    "\n",
    "# base_prefix = 'trial_abm_slOff'\n",
    "# base_prefix = 'bidir_pred_bidir'\n",
    "# base_prefix = 'dh'\n",
    "# base_prefix = 'gr-dual-n62'\n",
    "# base_prefix = 'bidir-ctrl-nslO'\n",
    "# base_prefix = 'DA-DA-pred'\n",
    "# base_prefix = 'ACH-to-DA'\n",
    "# base_prefix = 'DA-to-ACH__'\n",
    "\n",
    "# base_prefix = 'ind'\n",
    "# base_prefix = 'resid'\n",
    "# base_prefix = 'resid-chk'\n",
    "# base_prefix = 'resid-chk5'\n",
    "# base_prefix = 'test-res_trk'\n",
    "\n",
    "\n",
    "# base_prefix = 'f1-bkwd-sel'\n",
    "# base_prefix = 'f1-bkwd-sel-gACH2-rl'\n",
    "# base_prefix = 'f1-bkwd-sel-rDA2'\n",
    "# base_prefix = 'f1-bkwd-sel-gDA2'\n",
    "\n",
    "# base_prefix = 'f1-bkwd-sel-hypPrm-rDA'\n",
    "# base_prefix = 'f1-bkwd-sel-hypPrm-gACH'\n",
    "\n",
    "tmp_y_col_setup = 'gACH'\n",
    "# base_prefix = f'f1-bkwd-sel-{tmp_y_col_setup}3'\n",
    "# base_prefix = 'f1-bkwd-sel-rDA3'\n",
    "# base_prefix = 'f1-bkwd-sel-gDA3'\n",
    "\n",
    "# base_prefix = f'mse-tr-te-invstg3-{tmp_y_col_setup}'\n",
    "# base_prefix = f'mse-tr-te-invstg-ho-{tmp_y_col_setup}'\n",
    "# base_prefix = f'mse-tr-te-invstg-all-{tmp_y_col_setup}'\n",
    "# base_prefix = f'mse-tr-te-lim-bnds-{tmp_y_col_setup}'\n",
    "\n",
    "# base_prefix = f'bs-words-{tmp_y_col_setup}'\n",
    "base_prefix = f'cre-sr-7'\n",
    "\n",
    "\n",
    "# data_folder = 'fig1'\n",
    "# data_folder = 'fig3'\n",
    "# data_folder = 'fig3-dualhem'\n",
    "# data_folder = 'fig5/g1'\n",
    "# data_folder = 'fig5/g2'\n",
    "# data_folder = 'fig5/g3'\n",
    "# data_folder = 'fig5/g4'\n",
    "# data_folder = 'fig5/g5'\n",
    "\n",
    "# data_folder = 'fig3-dualhem'\n",
    "\n",
    "\n",
    "# for data_folder in ['fig5/g1', 'fig5/g2', 'fig5/g3', 'fig5/g4', 'fig5/g5']:\n",
    "for data_folder in ['fig5/g3', 'fig5/g4', 'fig5/g5']:\n",
    "\n",
    "\n",
    "\n",
    "    if data_folder == 'fig1':\n",
    "\n",
    "        wt_used = [\n",
    "                    # 'WT63', 'WT64'\n",
    "                   'WT63', 'WT64', 'WT65', 'WT66', 'WT67', 'WT68', 'WT69', # DA\n",
    "                   'WT57', 'WT58', 'WT59', 'WT60', 'WT61', 'WT53', 'WT55', 'WT56' # ACH\n",
    "                   ]\n",
    "\n",
    "    elif data_folder == 'fig3':\n",
    "        wt_used = ['WT61', 'WT63', 'WT64', 'WT44', 'WT51']\n",
    "    elif data_folder == 'fig3-dualhem':\n",
    "        wt_used = ['WT63', 'WT64', 'WT65']\n",
    "\n",
    "    elif data_folder == 'fig4/g1':\n",
    "        wt_used = ['S1233', 'S1234', 'S1260', 'S1246', 'S1248']\n",
    "    elif data_folder == 'fig4/g2':\n",
    "        wt_used = ['S1194', 'S1195', 'S1214', 'S1258', 'S1259']\n",
    "\n",
    "    elif data_folder == 'fig5/g1': # Drd2f/f control: S1417, 1419, 1421\n",
    "        # wt_used = ['S1417', 'S1419', 'S1421']\n",
    "        wt_used = ['S1417', 'S1419', 'S1421', 'S1460', 'S1462', 'S1473', 'S1474']\n",
    "    elif data_folder == 'fig5/g2': # Chat Cre X Drd2f/f : S1416, 1418, 1420, 1422\n",
    "        # wt_used = ['S1416', 'S1418', 'S1420', 'S1422']\n",
    "        wt_used = ['S1416', 'S1418', 'S1420', 'S1459', 'S1461', 'S1470', 'S1471', 'S1472']\n",
    "    elif data_folder == 'fig5/g3': # Chat Cre control: S1355-1358, S1374, S1376\n",
    "        # wt_used = ['S1355', 'S1356', 'S1357', 'S1358', 'S1374', 'S1376']\n",
    "        wt_used = ['S1355', 'S1356', 'S1357', 'S1358', 'S1374', 'S1376',\n",
    "                   'S1448', 'S1449', 'S1450', 'S1451']\n",
    "    elif data_folder == 'fig5/g4': # Chat Cre control: S1399-1401\n",
    "        # wt_used = ['S1399', 'S1400', 'S1401']\n",
    "        wt_used = ['S1399', 'S1400', 'S1401']\n",
    "    elif data_folder == 'fig5/g5':\n",
    "        # wt_used = ['S1355', 'S1356', 'S1357', 'S1358', 'S1374', 'S1376', 'S1399', 'S1400', 'S1401']\n",
    "        wt_used = ['S1355', 'S1356', 'S1357', 'S1358', 'S1374', 'S1376',\n",
    "                   'S1448', 'S1449', 'S1450', 'S1451'\n",
    "                   'S1399', 'S1400', 'S1401']\n",
    "    elif data_folder == 'fig5/g6':\n",
    "        wt_used = []\n",
    "    else:\n",
    "        raise ValueError('Unimplemented figure values.')\n",
    "\n",
    "    data_folder_join = '_'.join(data_folder.split('/'))\n",
    "\n",
    "\n",
    "    # ### Backwards Selection\n",
    "    # X_y_pairings = [\n",
    "    #     {'X_cols': {\n",
    "    #                 'rDA': (0, 0),\n",
    "    #                },\n",
    "    #      'y_col': tmp_y_col_setup},\n",
    "    #     {'X_cols': {\n",
    "    #                 'photometryCenterInIndex':(0,0),\n",
    "    #                 'photometryCenterOutIndex':(0,0),\n",
    "    #                 'photometrySideInIndex':(0,0),\n",
    "    #                 'photometrySideInIndexr':(0,0),                \n",
    "    #                 'photometrySideOutIndex':(0,0),\n",
    "    #                 'sl': (0,0),\n",
    "    #                 'spnnrOff': (0,0),\n",
    "    #                },\n",
    "    #      'y_col': tmp_y_col_setup + '_resid'},\n",
    "    #     {'X_cols': {\n",
    "    #                 'photometryCenterInIndex':(0,0),\n",
    "    #                 'photometryCenterOutIndex':(0,0),\n",
    "    #                 'photometrySideInIndex':(0,0),\n",
    "    #                 'photometrySideInIndexr':(0,0),                \n",
    "    #                 'photometrySideOutIndex':(0,0),\n",
    "    #                 'sl': (0,0),\n",
    "    #                 'spnnrOff': (0,0),\n",
    "    #                 'rDA': (0, 0),\n",
    "    #                },\n",
    "    #      'y_col': tmp_y_col_setup},\n",
    "    #     {'X_cols': {\n",
    "    #                 'photometryCenterInIndex':(0,0),\n",
    "    #                 'photometryCenterOutIndex':(0,0),\n",
    "\n",
    "    #                 'photometrySideInIndexAA':(0,0), 'photometrySideInIndexAa':(0,0),\n",
    "    #                 'photometrySideInIndexaA':(0,0), 'photometrySideInIndexaa':(0,0),\n",
    "    #                 'photometrySideInIndexAB':(0,0), 'photometrySideInIndexAb':(0,0),\n",
    "    #                 'photometrySideInIndexaB':(0,0), 'photometrySideInIndexab':(0,0),\n",
    "\n",
    "    #                 'photometrySideOutIndex':(0,0),\n",
    "    #                 'sl': (0,0),\n",
    "    #                 'spnnrOff': (0,0),\n",
    "    #                },\n",
    "    #      'y_col': tmp_y_col_setup},\n",
    "    # ]\n",
    "\n",
    "\n",
    "    # ## Start by saying this model works\n",
    "    # {\n",
    "    #     'photometryCenterInIndex':(0,0),\n",
    "    #     'photometryCenterOutIndex':(0,0),\n",
    "    #     'photometrySideInIndex':(0,0),\n",
    "    #     'photometrySideInIndexr':(0,0),                \n",
    "    #     'photometrySideOutIndex':(0,0),\n",
    "    #     'sl': (0,0),\n",
    "    #     'spnnrOff': (0,0),\n",
    "    # }\n",
    "    # # Go through & drop one by one\n",
    "\n",
    "\n",
    "    num_runs = 10\n",
    "\n",
    "    ### Backwards Selection\n",
    "    X_y_pairings_lst = []\n",
    "\n",
    "    X_y_pairings_lst += [[\n",
    "        {'X_cols': {\n",
    "                    'rDA':(0,0),\n",
    "                   },\n",
    "         'y_col': 'gACH',\n",
    "         'name': 'rDA-to-gACH'\n",
    "         },\n",
    "\n",
    "        {'X_cols': {\n",
    "                    'rDA':(0,0),\n",
    "                    'photometryCenterInIndex':(0,0),\n",
    "                    'photometryCenterOutIndex':(0,0),\n",
    "                    'photometrySideInIndex':(0,0),\n",
    "                    'photometrySideInIndexr':(0,0),\n",
    "                    'photometrySideOutIndex':(0,0),\n",
    "                    'sl': (0,0),\n",
    "                    'spnnrOff': (0,0),\n",
    "                   },\n",
    "         'y_col': 'gACH',\n",
    "         'name': 'simple+rDA-to-gACH'},\n",
    "\n",
    "        {'X_cols': {\n",
    "                    'rDA':(0,0),\n",
    "                    'photometryCenterInIndex':(0,0),\n",
    "                    'photometryCenterOutIndex':(0,0),\n",
    "                    'photometrySideInIndexAA':(0,0),\n",
    "                    'photometrySideInIndexAa':(0,0),\n",
    "                    'photometrySideInIndexaA':(0,0),\n",
    "                    'photometrySideInIndexaa':(0,0),\n",
    "                    'photometrySideInIndexAB':(0,0),\n",
    "                    'photometrySideInIndexAb':(0,0),\n",
    "                    'photometrySideInIndexaB':(0,0),\n",
    "                    'photometrySideInIndexab':(0,0),\n",
    "                    'photometrySideOutIndex':(0,0),\n",
    "                    'sl': (0,0),\n",
    "                    'spnnrOff': (0,0),\n",
    "                   },\n",
    "         'y_col': 'gACH',\n",
    "         'name': 'words+rDA-to-gACH'},\n",
    "\n",
    "    ]]\n",
    "\n",
    "    X_y_pairings_lst += [[\n",
    "        {'X_cols': {\n",
    "                    'gDA':(0,0),\n",
    "                   },\n",
    "         'y_col': 'gACH',\n",
    "         'name': 'gDA-to-gACH'\n",
    "         },\n",
    "\n",
    "         {'X_cols': {\n",
    "                    'gDA':(0,0),\n",
    "                    'photometryCenterInIndex':(0,0),\n",
    "                    'photometryCenterOutIndex':(0,0),\n",
    "                    'photometrySideInIndex':(0,0),\n",
    "                    'photometrySideInIndexr':(0,0),\n",
    "                    'photometrySideOutIndex':(0,0),\n",
    "                    'sl': (0,0),\n",
    "                    'spnnrOff': (0,0),\n",
    "                   },\n",
    "         'y_col': 'gACH',\n",
    "         'name': 'simple+gDA-to-gACH'},\n",
    "\n",
    "        {'X_cols': {\n",
    "                    'gDA':(0,0),\n",
    "                    'photometryCenterInIndex':(0,0),\n",
    "                    'photometryCenterOutIndex':(0,0),\n",
    "                    'photometrySideInIndexAA':(0,0),\n",
    "                    'photometrySideInIndexAa':(0,0),\n",
    "                    'photometrySideInIndexaA':(0,0),\n",
    "                    'photometrySideInIndexaa':(0,0),\n",
    "                    'photometrySideInIndexAB':(0,0),\n",
    "                    'photometrySideInIndexAb':(0,0),\n",
    "                    'photometrySideInIndexaB':(0,0),\n",
    "                    'photometrySideInIndexab':(0,0),\n",
    "                    'photometrySideOutIndex':(0,0),\n",
    "                    'sl': (0,0),\n",
    "                    'spnnrOff': (0,0),\n",
    "                   },\n",
    "         'y_col': 'gACH',\n",
    "         'name': 'words+gDA-to-gACH'},\n",
    "\n",
    "    ]]\n",
    "\n",
    "    X_y_pairings_lst += [[\n",
    "        {'X_cols': {\n",
    "                    'gACH':(0,0),\n",
    "                   },\n",
    "         'y_col': 'rDA',\n",
    "         'name': 'gACH-to-rDA'\n",
    "         },\n",
    "\n",
    "         {'X_cols': {\n",
    "                    'gACH':(0,0),\n",
    "                    'photometryCenterInIndex':(0,0),\n",
    "                    'photometryCenterOutIndex':(0,0),\n",
    "                    'photometrySideInIndex':(0,0),\n",
    "                    'photometrySideInIndexr':(0,0),\n",
    "                    'photometrySideOutIndex':(0,0),\n",
    "                    'sl': (0,0),\n",
    "                    'spnnrOff': (0,0),\n",
    "                   },\n",
    "         'y_col': 'rDA',\n",
    "         'name': 'simple+gACH-to-rDA'},\n",
    "\n",
    "        {'X_cols': {\n",
    "                    'gACH':(0,0),\n",
    "                    'photometryCenterInIndex':(0,0),\n",
    "                    'photometryCenterOutIndex':(0,0),\n",
    "                    'photometrySideInIndexAA':(0,0),\n",
    "                    'photometrySideInIndexAa':(0,0),\n",
    "                    'photometrySideInIndexaA':(0,0),\n",
    "                    'photometrySideInIndexaa':(0,0),\n",
    "                    'photometrySideInIndexAB':(0,0),\n",
    "                    'photometrySideInIndexAb':(0,0),\n",
    "                    'photometrySideInIndexaB':(0,0),\n",
    "                    'photometrySideInIndexab':(0,0),\n",
    "                    'photometrySideOutIndex':(0,0),\n",
    "                    'sl': (0,0),\n",
    "                    'spnnrOff': (0,0),\n",
    "                   },\n",
    "         'y_col': 'rDA',\n",
    "         'name': 'words+gACH-to-rDA'},\n",
    "\n",
    "    ]]\n",
    "\n",
    "    X_y_pairings_lst += [[\n",
    "        {'X_cols': {\n",
    "                    'gACH':(0,0),\n",
    "                   },\n",
    "         'y_col': 'gDA',\n",
    "         'name': 'gACH-to-gDA'\n",
    "         },\n",
    "\n",
    "         {'X_cols': {\n",
    "                    'gACH':(0,0),\n",
    "                    'photometryCenterInIndex':(0,0),\n",
    "                    'photometryCenterOutIndex':(0,0),\n",
    "                    'photometrySideInIndex':(0,0),\n",
    "                    'photometrySideInIndexr':(0,0),\n",
    "                    'photometrySideOutIndex':(0,0),\n",
    "                    'sl': (0,0),\n",
    "                    'spnnrOff': (0,0),\n",
    "                   },\n",
    "         'y_col': 'gDA',\n",
    "         'name': 'simple+gACH-to-gDA'},\n",
    "\n",
    "        {'X_cols': {\n",
    "                    'gACH':(0,0),\n",
    "                    'photometryCenterInIndex':(0,0),\n",
    "                    'photometryCenterOutIndex':(0,0),\n",
    "                    'photometrySideInIndexAA':(0,0),\n",
    "                    'photometrySideInIndexAa':(0,0),\n",
    "                    'photometrySideInIndexaA':(0,0),\n",
    "                    'photometrySideInIndexaa':(0,0),\n",
    "                    'photometrySideInIndexAB':(0,0),\n",
    "                    'photometrySideInIndexAb':(0,0),\n",
    "                    'photometrySideInIndexaB':(0,0),\n",
    "                    'photometrySideInIndexab':(0,0),\n",
    "                    'photometrySideOutIndex':(0,0),\n",
    "                    'sl': (0,0),\n",
    "                    'spnnrOff': (0,0),\n",
    "                   },\n",
    "         'y_col': 'gDA',\n",
    "         'name': 'words+gACH-to-gDA'},\n",
    "\n",
    "    ]]\n",
    "\n",
    "    plot_width = 2\n",
    "    max_cols_len_lst = [max([len(_['X_cols']) for _ in inner_list]) for inner_list in X_y_pairings_lst]\n",
    "    plot_rows_lst = [_//plot_width + (_%plot_width > 0)*1 for _ in max_cols_len_lst]\n",
    "\n",
    "    drop_cols_basis = [\n",
    "        'nTrial', 'nTrial_filenum',\n",
    "        'nEndTrial',\n",
    "        'cpn', 'cpx',\n",
    "        'spnnr',\n",
    "        'spxnr',\n",
    "        'spnr', 'spxr',\n",
    "\n",
    "        'photometryCenterInIndex', 'photometryCenterOutIndex',\n",
    "        'photometrySideInIndexr', 'photometrySideInIndexnr',\n",
    "        'photometrySideOutIndex', 'spnnrOff',\n",
    "\n",
    "        'photometrySideInIndexAA', 'photometrySideInIndexAa',\n",
    "        'photometrySideInIndexaA', 'photometrySideInIndexaa',\n",
    "        'photometrySideInIndexAB', 'photometrySideInIndexAb',\n",
    "        'photometrySideInIndexaB', 'photometrySideInIndexab',\n",
    "\n",
    "#         'photometrySideOutIndexAA', 'photometrySideOutIndexAa',\n",
    "#         'photometrySideOutIndexaA', 'photometrySideOutIndexaa',\n",
    "#         'photometrySideOutIndexAB', 'photometrySideOutIndexAb',\n",
    "#         'photometrySideOutIndexaB', 'photometrySideOutIndexab',\n",
    "\n",
    "        'sl',\n",
    "        'slOff'\n",
    "    ]\n",
    "\n",
    "    # create_folder_if_not_exists(dir)\n",
    "\n",
    "    base_folder = '/home/josh/github-repos/sabatinilab-glm/sglm/outputs'\n",
    "\n",
    "    ssave_folder = 'models/ssave'\n",
    "    all_models_folder = 'models/all_models'\n",
    "    all_data_folder = 'models/all_data'\n",
    "    all_reconstruct_folder = 'reports/figures/all_reconstruct'\n",
    "    all_coeffs_folder = 'reports/figures/all_coeffs'\n",
    "    best_reconstruct_folder = 'reports/figures/best_reconstruct'\n",
    "    best_coeffs_npy_folder = 'reports/coeffs/best_coeffs'\n",
    "    best_resids_npy_folder = 'reports/residuals/best_resids'\n",
    "    best_combined_coeffs_folder = 'reports/coeffs/best_combined_coeffs'\n",
    "    best_coeffs_folder = 'reports/figures/best_coeffs'\n",
    "\n",
    "    all_models_folder = 'models'\n",
    "\n",
    "    avg_reconstruct_basename = 'arr'\n",
    "    all_betas_basename = 'betas'\n",
    "    model_c_basename = 'coeffs'\n",
    "    model_i_basename = 'intercept'\n",
    "    tmp_data_basename = 'tmp_data'\n",
    "\n",
    "\n",
    "\n",
    "    score_method = 'r2'\n",
    "\n",
    "    # Select hyper parameters for GLM to use for model selection\n",
    "    # Step 1: Create a dictionary of lists for these relevant keywords...\n",
    "    kwargs_iterations = {\n",
    "        'alpha': [0],\n",
    "        'l1_ratio': [0],\n",
    "\n",
    "        # 'alpha': [0.0, 0.001, 0.01, 0.1, 1.0],\n",
    "        # 'l1_ratio': [0.0, 0.0001, 0.001, 0.01],\n",
    "    }\n",
    "\n",
    "    # Step 2: Create a dictionary for the fixed keyword arguments that do not require iteration...\n",
    "    kwargs_fixed = {\n",
    "        'max_iter': 10000,\n",
    "        'fit_intercept': False\n",
    "    }\n",
    "\n",
    "    # neg_order, pos_order = -14, 14\n",
    "    # folds = 50\n",
    "    # folds = 10\n",
    "    folds = 10\n",
    "    # folds = 1\n",
    "    pholdout = 0.2\n",
    "    pgss = 0.2\n",
    "\n",
    "    # Step 3: Generate iterable list of keyword sets for possible combinations\n",
    "    glm_kwarg_lst = sglm_cv.generate_mult_params(kwargs_iterations, kwargs_fixed)\n",
    "\n",
    "    all_coeff_dfs = []\n",
    "\n",
    "    multi_start = time.time()\n",
    "\n",
    "    for iXyp, X_y_pairings in enumerate(X_y_pairings_lst):\n",
    "\n",
    "        widest_orders = [{'X_cols': smf.X_cols_dict_to_default(_['X_cols'], neg_order, pos_order),\n",
    "                        'y_col': _['y_col']} for _ in X_y_pairings]\n",
    "        widest_orders = smf.xy_pairs_to_widest_orders(widest_orders)\n",
    "\n",
    "        max_cols_len = max_cols_len_lst[iXyp]\n",
    "        plot_rows = plot_rows_lst[iXyp]\n",
    "\n",
    "        for multifile_fit in multifile_fit_list:\n",
    "            data_folder_join = '_'.join(data_folder.split('/'))\n",
    "\n",
    "            # prefix = f'{data_folder}-{multifile_fit}-words-recons'\n",
    "            prefix = f'{data_folder_join}/{multifile_fit}/{base_prefix}_{iXyp}{ft_str}'\n",
    "\n",
    "            create_folder_if_not_exists(f'{base_folder}/{prefix}')\n",
    "            create_folder_if_not_exists(f'{base_folder}/{prefix}/{best_coeffs_folder}')\n",
    "            create_folder_if_not_exists(f'{base_folder}/{prefix}/{best_coeffs_npy_folder}')\n",
    "            create_folder_if_not_exists(f'{base_folder}/{prefix}/{best_reconstruct_folder}')\n",
    "            create_folder_if_not_exists(f'{base_folder}/{prefix}/{best_resids_npy_folder}')\n",
    "            create_folder_if_not_exists(f'{base_folder}/{prefix}/{best_combined_coeffs_folder}')\n",
    "            create_folder_if_not_exists(f'{base_folder}/{prefix}/{all_models_folder}/coeffs')\n",
    "            create_folder_if_not_exists(f'{base_folder}/{prefix}/{all_models_folder}/intercepts')\n",
    "            create_folder_if_not_exists(f'{base_folder}/{prefix}/{all_coeffs_folder}')\n",
    "            create_folder_if_not_exists(f'{base_folder}/{prefix}/{all_reconstruct_folder}')\n",
    "            create_folder_if_not_exists(f'{base_folder}/{prefix}/{best_reconstruct_folder}')\n",
    "            os.popen(f'cp {nb_full_path} {base_folder}/{prefix}/{nb_name}') \n",
    "\n",
    "            # Load Signal Data\n",
    "            signal_files = []\n",
    "            mouse_names = []\n",
    "            for wt in wt_used:\n",
    "                addl_sig_files = glob.glob(f'../../data/interim/{data_folder}/GLM_SIGNALS_INTERIM_{wt}_*')\n",
    "                signal_files += addl_sig_files\n",
    "                mouse_names += [wt] * len(addl_sig_files)\n",
    "\n",
    "            if multifile_fit == 'all':\n",
    "                combo_dfs, X_cols_sftd, _ = smf.multi_file_analysis_prep(signal_files, widest_orders,)\n",
    "                combo_fns = ['_'.join(wt_used).replace('WT', '').replace('S', '')]\n",
    "                mouse_names = combo_fns\n",
    "            elif multifile_fit == 'by_mouse':\n",
    "                combo_dfs = []\n",
    "                X_cols_sftd_lst = []\n",
    "                combo_fns = []\n",
    "                mouse_names_2 = []\n",
    "                for mouse_id in wt_used:\n",
    "                    mouse_id_files = [_ for _ in signal_files if mouse_id in _]\n",
    "                    mouse_names_2 += [mouse_id]\n",
    "                    print('mouse_id', mouse_id)\n",
    "                    combo_dfs_tmp, X_cols_sftd_tmp, _ = smf.multi_file_analysis_prep(mouse_id_files, widest_orders,)\n",
    "                    combo_dfs += combo_dfs_tmp\n",
    "                    X_cols_sftd_lst.append(X_cols_sftd_tmp)\n",
    "                    combo_fns.append(mouse_id)\n",
    "\n",
    "                for xcsl in X_cols_sftd_lst:\n",
    "                    if xcsl != X_cols_sftd_lst[0]:\n",
    "                        raise ValueError('X_cols_sftd_lst should contain the same elements for every entry')\n",
    "                mouse_names = mouse_names_2\n",
    "\n",
    "                X_cols_sftd = X_cols_sftd_lst[0]\n",
    "\n",
    "            elif multifile_fit == 'single':\n",
    "                combo_dfs, X_cols_sftd, combo_fns = smf.single_file_analysis_prep(signal_files, widest_orders,)\n",
    "                mouse_names = mouse_names\n",
    "            else:\n",
    "                raise ValueError('multifile_fit must be \"all\", \"single\", or \"by_mouse\"')\n",
    "\n",
    "            # print(combo_dfs)\n",
    "\n",
    "            start = time.time()\n",
    "\n",
    "            results_dict = {}\n",
    "\n",
    "            for file_num in range(len(combo_dfs)):\n",
    "\n",
    "\n",
    "                # Load Table Data\n",
    "                signal_df = combo_dfs[file_num]\n",
    "                signal_fn = combo_fns[file_num]\n",
    "                mouse_id = mouse_names[file_num]\n",
    "\n",
    "                fn = signal_fn.split('.')[0].split('/')[-1]\n",
    "\n",
    "                print(mouse_names, file_num, mouse_id)\n",
    "\n",
    "                dfrel_basis = signal_df.reset_index(drop=False).copy()\n",
    "                print('dfrel_basis', dfrel_basis.shape)\n",
    "\n",
    "                signal_filename_out = 'FINAL_' + signal_fn.split('/')[-1].replace('GLM_SIGNALS_INTERIM_', '').replace('txt', 'csv') + '.csv'\n",
    "                print(signal_filename_out)\n",
    "\n",
    "                dfrel_basis['mouse_id'] = mouse_id\n",
    "                dfrel_basis.set_index(['file_num'], append=True, inplace=True)\n",
    "\n",
    "\n",
    "                dfrr_cols = ['nTrial', 'nTrial_filenum', 'nEndTrial', 'wi_trial_keep', 'gDA', 'gACH', 'rDA',\n",
    "                'diffTrialNums', 'dupe',\n",
    "                'photometryCenterInIndex', 'photometryCenterOutIndex',\n",
    "                'photometrySideInIndex',\n",
    "                'photometrySideInIndexr', 'photometrySideInIndexnr',\n",
    "                'photometrySideOutIndex', 'spnnrOff', 'sl',\n",
    "\n",
    "                'photometrySideInIndexAA', 'photometrySideInIndexAa',\n",
    "                'photometrySideInIndexaA','photometrySideInIndexaa',\n",
    "                'photometrySideInIndexAB', 'photometrySideInIndexAb',\n",
    "                'photometrySideInIndexaB','photometrySideInIndexab',\n",
    "\n",
    "                ]\n",
    "\n",
    "\n",
    "                # dfrel_resids = dfrel_basis[['nTrial', 'wi_trial_keep', 'gDA', 'gACH', 'rDA']].copy()\n",
    "                dfrel_resids = dfrel_basis[dfrr_cols].copy()\n",
    "\n",
    "                holdout_score_rnd = None\n",
    "\n",
    "                dfrel_resids_setup = pd.DataFrame()\n",
    "                dfrel_resids_holdout = pd.DataFrame()\n",
    "\n",
    "                for irun in range(num_runs):\n",
    "                    full_drop_basis = []\n",
    "                    y_col_lst = []\n",
    "                    for X_y_dct in X_y_pairings:\n",
    "                        X_cols_basis = X_y_dct['X_cols']\n",
    "                        y_col = X_y_dct['y_col']\n",
    "                        X_cols_sftd_basis = bf.col_shift_bounds_dict_to_col_list(X_cols_basis, X_cols_sftd)\n",
    "                        full_drop_basis += X_cols_sftd_basis\n",
    "\n",
    "                        if y_col[-len('_resid'):] != '_resid':\n",
    "                            y_col_lst += [y_col]\n",
    "                    full_drop_basis = sorted(list(set(full_drop_basis)))\n",
    "                    y_col_drop_basis = sorted(list(set(y_col_lst)))\n",
    "                    full_drop_basis = sorted(list(set(drop_cols_basis + full_drop_basis + y_col_drop_basis)))\n",
    "                    \n",
    "                    keep_cols = full_drop_basis + y_col_drop_basis + dfrr_cols + drop_cols_basis + X_cols_sftd_basis\n",
    "                    drop_cols = [_ for _ in dfrel_basis.columns if _ not in keep_cols and '_resid' not in _]\n",
    "                    \n",
    "                    if fix_training:\n",
    "                        print('-',y_col_lst)\n",
    "\n",
    "                        dfrel_ft = dfrel_basis.drop(drop_cols, axis=1)\n",
    "                        # print('full_drop_basis', full_drop_basis)\n",
    "                        # print('y_col_drop_basis', y_col_drop_basis)\n",
    "                        # print('dfrel_ft', len(dfrel_ft))\n",
    "                        srs_a = (dfrel_ft[full_drop_basis].isna().sum(axis=1))\n",
    "                        srs_b = (dfrel_ft[y_col_drop_basis] == 0).sum(axis=1)\n",
    "                        # print('srs_a', srs_a[srs_a > 0])\n",
    "                        # print('srs_b', srs_b[srs_b > 0])\n",
    "\n",
    "                        dfrel_ft = dfrel_ft[(dfrel_ft[full_drop_basis].isna().sum(axis=1) == 0)&((dfrel_ft[y_col_drop_basis] == 0).sum(axis=1) == 0)]\n",
    "                        if dfrel_ft.shape[0] == 0:\n",
    "                            print(f'No datapoints found for non-NaN dropcols & non-zero ycols for fixed_training: {prefix}_{fn}')\n",
    "                            continue\n",
    "\n",
    "                        dfrel_ft_setup, dfrel_ft_holdout, holdout = models.split_data.holdout_splits(dfrel_ft, id_cols=['nTrial_filenum'], perc_holdout=pholdout)\n",
    "                        dfrel_ft_setup, dfrel_ft_holdout = (dfrel_ft_setup.copy()\n",
    "                                                            ,\n",
    "                                                            dfrel_ft_holdout.copy()\n",
    "                                                           )\n",
    "\n",
    "                        dfrel_resids_setup = dfrel_ft_setup[dfrr_cols].copy()\n",
    "                        dfrel_resids_holdout = dfrel_ft_holdout[dfrr_cols].copy()\n",
    "\n",
    "\n",
    "\n",
    "                    for iXyd, X_y_dct in enumerate(X_y_pairings):\n",
    "                        dfrel = dfrel_basis.drop(drop_cols, axis=1)\n",
    "                        X_cols_basis = X_y_dct['X_cols']\n",
    "                        y_col = X_y_dct['y_col']\n",
    "                        name = X_y_dct['name']\n",
    "                        X_cols_sftd_basis = bf.col_shift_bounds_dict_to_col_list(X_cols_basis, X_cols_sftd)\n",
    "\n",
    "\n",
    "                        run_id = f'{fn}_{y_col}_{iXyd}_run_num={irun}' if num_runs > 1 else f'{fn}_{y_col}_{iXyd}'\n",
    "\n",
    "                        # print('dfrel.columns', list(dfrel.columns))\n",
    "                        #### Revise line to reduce length / number of checks\n",
    "\n",
    "                        dfrel = dfrel[(dfrel[drop_cols_basis + X_cols_sftd_basis + [y_col]].isna().sum(axis=1) == 0)&(dfrel[y_col] != 0)]\n",
    "                        if dfrel.shape[0] == 0:\n",
    "                            print(f'No datapoints found for non-NaN dropcols & non-zero ycols for run id: {run_id}.')\n",
    "                            continue\n",
    "\n",
    "                        if fix_training:\n",
    "                            assert np.all(dfrel_ft.fillna(0) == dfrel.fillna(0))\n",
    "                            dfrel = dfrel_ft.copy()\n",
    "                            dfrel_setup, dfrel_holdout = dfrel_ft_setup.copy(), dfrel_ft_holdout.copy()\n",
    "                        else:\n",
    "                            dfrel_setup, dfrel_holdout, holdout = models.split_data.holdout_splits(dfrel, id_cols=['nTrial_filenum'], perc_holdout=pholdout)\n",
    "                            dfrel_setup, dfrel_holdout = dfrel_setup.copy(), dfrel_holdout.copy()\n",
    "\n",
    "\n",
    "                        print('dfr.shape', dfrel.shape)\n",
    "\n",
    "                        print(f'> Included file_nums for y_col {y_col}:', list(dfrel.reset_index()['file_num'].unique()))\n",
    "\n",
    "\n",
    "                        # # kfold_cv_idx = models.split_data.cv_idx_by_trial_id(dfrel_setup, trial_id_columns=['nTrial'], num_folds=folds, test_size=pgss)\n",
    "                        # if len(glm_kwarg_lst) > 1:\n",
    "                        #     # Generate cross-validation (technically, group / shuffle split) sets for training / model selection\n",
    "                        #     kfold_cv_idx = models.split_data.cv_idx_by_trial_id(dfrel_setup, trial_id_columns=['nTrial'], num_folds=folds, test_size=pgss)\n",
    "                        #     print('size>1:',kfold_cv_idx)\n",
    "                        # else:\n",
    "                        #     kfold_cv_idx = models.split_data.cv_idx_by_trial_id(dfrel_setup, trial_id_columns=['nTrial'], num_folds=1, test_size=pgss)\n",
    "                        #     print('size=1:',kfold_cv_idx)\n",
    "                        # kfold_cv_idx = models.split_data.cv_idx_by_trial_id(dfrel_setup, trial_id_columns=['nTrial'], num_folds=folds, test_size=pgss)\n",
    "\n",
    "\n",
    "\n",
    "                        prediction_X_cols = [_ for _ in X_cols_basis if _ not in ['nTrial']]\n",
    "                        prediction_X_cols_sftd = [_ for _ in X_cols_sftd_basis if _ not in ['nTrial']]\n",
    "\n",
    "                        X_witi, y_witi, X_noiti, y_noiti = train_model.get_xy_all_noniti(dfrel, prediction_X_cols_sftd, y_col, noniticol='wi_trial_keep')\n",
    "                        X_setup_witi, y_setup_witi, X_setup_noiti, y_setup_noiti = train_model.get_xy_all_noniti(dfrel_setup, prediction_X_cols_sftd, y_col, noniticol='wi_trial_keep')\n",
    "                        X_holdout_witi, y_holdout_witi, X_holdout_noiti, y_holdout_noiti = train_model.get_xy_all_noniti(dfrel_holdout, prediction_X_cols_sftd,\n",
    "                                                                                                                        y_col, noniticol='wi_trial_keep')\n",
    "\n",
    "\n",
    "                        dfrel_witi, _, dfrel_noiti, _ = train_model.get_xy_all_noniti(dfrel, list(dfrel.columns), y_col, noniticol='wi_trial_keep')\n",
    "                        dfrel_setup_witi, _, dfrel_setup_noiti, _ = train_model.get_xy_all_noniti(dfrel_setup, list(dfrel_setup.columns), y_col, noniticol='wi_trial_keep')\n",
    "                        dfrel_holdout_witi, _, dfrel_holdout_noiti, _ = train_model.get_xy_all_noniti(dfrel_holdout, list(dfrel_holdout.columns), y_col, noniticol='wi_trial_keep')\n",
    "\n",
    "\n",
    "                        # Generate cross-validation (technically, group / shuffle split) sets for training / model selection\n",
    "                        kfold_cv_idx = models.split_data.cv_idx_by_trial_id(dfrel_setup_noiti, trial_id_columns=['nTrial_filenum'], num_folds=folds, test_size=pgss)\n",
    "\n",
    "                        # X_all_witi, y_all_witi, X_all_noiti, y_all_noiti = train_model.get_xy_all_noniti(dfrel, prediction_X_cols_sftd,\n",
    "                        #                                                                                  y_col, noniticol='wi_trial_keep')\n",
    "\n",
    "                        print('X_setup.columns:', X_setup_noiti.columns)\n",
    "                        \n",
    "                        print('Variable Sizes:')\n",
    "                        for name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()),\n",
    "                                                 key= lambda x: -x[1])[:30]:\n",
    "                            print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))\n",
    "\n",
    "                        best_score, best_score_std, best_params, best_model, cv_results = models.sglm_cv.simple_cv_fit(X_setup_noiti, y_setup_noiti, kfold_cv_idx, glm_kwarg_lst, model_type='Normal',\n",
    "                                                                                                                    verbose=0, score_method=score_method)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        eval.print_best_model_info(X_setup_noiti, best_score, best_params, best_model, start)\n",
    "                        glm, holdout_score, holdout_neg_mse_score = eval.training_fit_holdout_score(X_setup_noiti, y_setup_noiti, X_holdout_noiti, y_holdout_noiti, best_params)\n",
    "\n",
    "\n",
    "                        dfrel['pred'] = glm.predict(X_witi)\n",
    "                        dfrel_setup['pred'] = glm.predict(X_setup_witi)\n",
    "                        dfrel_holdout['pred'] = glm.predict(X_holdout_witi)\n",
    "\n",
    "                        # Collect\n",
    "                        results_dict[f'{run_id}'] = {'holdout_score':holdout_score,\n",
    "                                                    'holdout_neg_mse_score':holdout_neg_mse_score,\n",
    "                                                    'best_score':best_score,\n",
    "                                                    'best_params':best_params,\n",
    "                                                    'all_models':sorted([(_['cv_R2_score'],\n",
    "                                                                            _['cv_mse_score'],\n",
    "                                                                            eval.calc_l1(_['cv_coefs']),\n",
    "                                                                            eval.calc_l2(_['cv_coefs']),\n",
    "                                                                            _['glm_kwargs']) for _ in cv_results['full_cv_results']], key=lambda x: -x[0])\n",
    "                                                    }\n",
    "                        print(f'Holdout Score: {holdout_score}')\n",
    "\n",
    "                        # Generate and save plots of the beta coefficients\n",
    "                        X_cols_plot = prediction_X_cols\n",
    "                        X_cols_sftd_plot = prediction_X_cols_sftd\n",
    "\n",
    "\n",
    "                        holdout_score_rnd = np.round(holdout_score, 4)\n",
    "                        best_beta_fn = f'{base_folder}/{prefix}/{best_coeffs_folder}/{run_id}_best_{all_betas_basename}_R2_{holdout_score_rnd}.png'\n",
    "\n",
    "#                         tr_score = dfrel_setup\n",
    "\n",
    "                        setup_df = pd.DataFrame(np.concatenate([np.array([glm.intercept_]), glm.coef_], axis=0).reshape(1,-1),\n",
    "                                    index=[run_id], columns=['int']+prediction_X_cols_sftd)\n",
    "                        setup_df['mouse_id'] = mouse_id\n",
    "                        setup_df['channel_name'] = y_col + '_' + str(iXyd) + f'_run_num={irun}' if num_runs > 1 else y_col + '_' + str(iXyd)\n",
    "\n",
    "                        print(len(cv_results), cv_results.keys())\n",
    "\n",
    "                        setup_df['name'] = name\n",
    "\n",
    "                        # Only get R^2 values if only a single model fit\n",
    "                        if len(cv_results['full_cv_results']) == 1:\n",
    "\n",
    "                            assert holdout_neg_mse_score == glm.neg_mse_score(X_holdout_noiti, y_holdout_noiti)\n",
    "\n",
    "                            setup_df['mse_tr'] = -glm.neg_mse_score(X_setup_noiti, y_setup_noiti)\n",
    "                            setup_df['mse_cv'] = cv_results['full_cv_results'][0]['cv_mse_score']\n",
    "                            setup_df['mse_te'] = -glm.neg_mse_score(X_holdout_noiti, y_holdout_noiti) #-holdout_neg_mse_score\n",
    "\n",
    "\n",
    "                            setup_df['r2_tr'] = glm.r2_score(X_setup_noiti, y_setup_noiti)\n",
    "                            setup_df['r2_cv'] = cv_results['full_cv_results'][0]['cv_R2_score']\n",
    "                            setup_df['r2_te'] = glm.r2_score(X_holdout_noiti, y_holdout_noiti) #-holdout_neg_mse_score\n",
    "\n",
    "                            # setup_df['tr_num_r'] = dfrel_setup\n",
    "                            # setup_df['tr_num_nr'] = dfrel_setup\n",
    "                            # setup_df['cv_num_r'] = dfrel_setup\n",
    "                            # setup_df['cv_num_nr'] = dfrel_setup\n",
    "                            # setup_df['te_num_r'] = dfrel_setup\n",
    "                            # setup_df['te_num_nr'] = dfrel_setup\n",
    "                            # print('Here')\n",
    "\n",
    "                        else: \n",
    "                            setup_df['mse_tr'] = 0.0\n",
    "                            setup_df['mse_cv'] = 0.0\n",
    "                            setup_df['mse_te'] = 0.0\n",
    "\n",
    "                            setup_df['r2_tr'] = 0.0\n",
    "                            setup_df['r2_cv'] = 0.0\n",
    "                            setup_df['r2_te'] = 0.0\n",
    "\n",
    "                        multi_end = time.time()\n",
    "                        setup_df['timestamp'] = str(multi_end - multi_start) + ' s'\n",
    "\n",
    "                        setup_df = setup_df.set_index(['mouse_id', 'channel_name', 'name', 'mse_tr', 'mse_cv', 'mse_te', 'r2_tr', 'r2_cv', 'r2_te', 'timestamp'], append=True)\n",
    "\n",
    "                        tot_trials_setup = dfrel_setup_noiti['photometrySideInIndex'].sum()\n",
    "                        tot_trials_holdout = dfrel_holdout_noiti['photometrySideInIndex'].sum()\n",
    "\n",
    "                        setup_df['AA_cnt_tr'] = dfrel_setup_noiti['photometrySideInIndexAA'].sum()/tot_trials_setup\n",
    "                        setup_df['Aa_cnt_tr'] = dfrel_setup_noiti['photometrySideInIndexAa'].sum()/tot_trials_setup\n",
    "                        setup_df['aA_cnt_tr'] = dfrel_setup_noiti['photometrySideInIndexaA'].sum()/tot_trials_setup\n",
    "                        setup_df['aa_cnt_tr'] = dfrel_setup_noiti['photometrySideInIndexaa'].sum()/tot_trials_setup\n",
    "                        setup_df['AB_cnt_tr'] = dfrel_setup_noiti['photometrySideInIndexAB'].sum()/tot_trials_setup\n",
    "                        setup_df['Ab_cnt_tr'] = dfrel_setup_noiti['photometrySideInIndexAb'].sum()/tot_trials_setup\n",
    "                        setup_df['aB_cnt_tr'] = dfrel_setup_noiti['photometrySideInIndexaB'].sum()/tot_trials_setup\n",
    "                        setup_df['ab_cnt_tr'] = dfrel_setup_noiti['photometrySideInIndexab'].sum()/tot_trials_setup\n",
    "\n",
    "                        setup_df['AA_cnt_te'] = dfrel_holdout_noiti['photometrySideInIndexAA'].sum()/tot_trials_holdout\n",
    "                        setup_df['Aa_cnt_te'] = dfrel_holdout_noiti['photometrySideInIndexAa'].sum()/tot_trials_holdout\n",
    "                        setup_df['aA_cnt_te'] = dfrel_holdout_noiti['photometrySideInIndexaA'].sum()/tot_trials_holdout\n",
    "                        setup_df['aa_cnt_te'] = dfrel_holdout_noiti['photometrySideInIndexaa'].sum()/tot_trials_holdout\n",
    "                        setup_df['AB_cnt_te'] = dfrel_holdout_noiti['photometrySideInIndexAB'].sum()/tot_trials_holdout\n",
    "                        setup_df['Ab_cnt_te'] = dfrel_holdout_noiti['photometrySideInIndexAb'].sum()/tot_trials_holdout\n",
    "                        setup_df['aB_cnt_te'] = dfrel_holdout_noiti['photometrySideInIndexaB'].sum()/tot_trials_holdout\n",
    "                        setup_df['ab_cnt_te'] = dfrel_holdout_noiti['photometrySideInIndexab'].sum()/tot_trials_holdout\n",
    "\n",
    "\n",
    "                        setup_df.to_csv(f'{base_folder}/{prefix}/{best_coeffs_npy_folder}/{run_id}_best_coeffs_R2_{holdout_score_rnd}.csv', index=True, header=True)\n",
    "                        all_coeff_dfs.append(setup_df)\n",
    "\n",
    "\n",
    "                        # visualize.plot_all_beta_coefs(glm.coef_, X_cols_plot,\n",
    "                        #                                 X_cols_sftd_plot,\n",
    "                        #                                 # plot_width=4,\n",
    "                        #                                 plot_width=plot_width,\n",
    "                        #                                 plot_rows=plot_rows,\n",
    "                        #                                 y_lims=(-3.0, 3.0),\n",
    "                        #                                 binsize=54,\n",
    "                        #                                 filename=best_beta_fn,\n",
    "                        #                                 plot_name=f'Best Coeffs - {run_id}  {best_params}'\n",
    "                        #                                 )\n",
    "\n",
    "\n",
    "                        # best_rcnstrct_fn = f'{base_folder}/{prefix}/{best_reconstruct_folder}/{run_id}_best_{avg_reconstruct_basename}_R2_{holdout_score_rnd}.png'\n",
    "\n",
    "\n",
    "                        # visualize.plot_avg_reconstructions_v2(dfrel_holdout,\n",
    "                        #                             alignment_col_lst=[ #'cpn', 'spnr', 'spnnr',\n",
    "                        #                                                 # 'photometryCenterInIndex', #'photometryCenterOutIndex',\n",
    "                        #                                                 'photometrySideInIndexr', 'photometrySideInIndexnr',\n",
    "                        #                                                 'photometrySideOutIndexr', 'photometrySideOutIndexnr',\n",
    "\n",
    "                        #                                                 'photometrySideInIndexAA', 'photometrySideInIndexAa',\n",
    "                        #                                                 'photometrySideInIndexaA','photometrySideInIndexaa',\n",
    "                        #                                                 'photometrySideInIndexAB', 'photometrySideInIndexAb',\n",
    "                        #                                                 'photometrySideInIndexaB','photometrySideInIndexab',\n",
    "\n",
    "                        #                                                 'photometryCenterInIndex', #'photometryCenterOutIndex',\n",
    "\n",
    "                        #                                                 'photometrySideInIndex',\n",
    "\n",
    "                        #                                                 # 'photometrySideOutIndexAA', 'photometrySideOutIndexAa',\n",
    "                        #                                                 # 'photometrySideOutIndexaA', 'photometrySideOutIndexaa',\n",
    "                        #                                                 # 'photometrySideOutIndexAB', 'photometrySideOutIndexAb',\n",
    "                        #                                                 # 'photometrySideOutIndexaB', 'photometrySideOutIndexab',\n",
    "                        #                                         ],\n",
    "\n",
    "                        #                             channel=y_col,\n",
    "                        #                             binsize = 54,\n",
    "                        #                             # plot_width=4,\n",
    "                        #                             plot_width=2,\n",
    "                        #                             min_time = -20,\n",
    "                        #                             max_time = 30,\n",
    "                        #                             min_signal = -3.0,\n",
    "                        #                             max_signal = 3.0,\n",
    "                        #                             file_name=best_rcnstrct_fn,\n",
    "                        #                             title=f'Best Average Reconstruction - {run_id}  {best_params}'\n",
    "                        #                             )\n",
    "\n",
    "                        # best_rcnstrct_fn = f'{base_folder}/{prefix}/{best_reconstruct_folder}/{run_id}_tr+ho_best_{avg_reconstruct_basename}_R2_{holdout_score_rnd}.png'\n",
    "\n",
    "                        # visualize.plot_avg_reconstructions_v2(dfrel,\n",
    "                        #                             alignment_col_lst=[ #'cpn', 'spnr', 'spnnr',\n",
    "                        #                                                 # 'photometryCenterInIndex', #'photometryCenterOutIndex',\n",
    "                        #                                                 'photometrySideInIndexr', 'photometrySideInIndexnr',\n",
    "                        #                                                 'photometrySideOutIndexr', 'photometrySideOutIndexnr',\n",
    "\n",
    "                        #                                                 'photometrySideInIndexAA', 'photometrySideInIndexAa',\n",
    "                        #                                                 'photometrySideInIndexaA','photometrySideInIndexaa',\n",
    "                        #                                                 'photometrySideInIndexAB', 'photometrySideInIndexAb',\n",
    "                        #                                                 'photometrySideInIndexaB','photometrySideInIndexab',\n",
    "\n",
    "                        #                                                 'photometryCenterInIndex', #'photometryCenterOutIndex',\n",
    "\n",
    "                        #                                                 'photometrySideInIndex',\n",
    "\n",
    "                        #                                                 # 'photometrySideOutIndexAA', 'photometrySideOutIndexAa',\n",
    "                        #                                                 # 'photometrySideOutIndexaA', 'photometrySideOutIndexaa',\n",
    "                        #                                                 # 'photometrySideOutIndexAB', 'photometrySideOutIndexAb',\n",
    "                        #                                                 # 'photometrySideOutIndexaB', 'photometrySideOutIndexab',\n",
    "                        #                                         ],\n",
    "\n",
    "                        #                             channel=y_col,\n",
    "                        #                             binsize = 54,\n",
    "                        #                             # plot_width=4,\n",
    "                        #                             plot_width=2,\n",
    "                        #                             min_time = -20,\n",
    "                        #                             max_time = 30,\n",
    "                        #                             min_signal = -3.0,\n",
    "                        #                             max_signal = 3.0,\n",
    "                        #                             file_name=best_rcnstrct_fn,\n",
    "                        #                             title=f'Best Average Reconstruction  Training + Holdout - {run_id}  {best_params}'\n",
    "                        #                             )\n",
    "\n",
    "\n",
    "                        # dfrel_resids = dfrel[['file_num', 'nTrial', 'wi_trial_keep', 'gDA', 'gACH', 'rDA', 'pred']].copy()\n",
    "                        # dfrel_resids['mouse_id'] = mouse_id\n",
    "                        # dfrel_resids['channel_name'] = y_col\n",
    "\n",
    "                        # dfrel_resids.set_index(['mouse_id', 'channel_name', 'file_num', 'nTrial'], inplace=True)\n",
    "                        # dfrel_resids.to_csv(f'{base_folder}/{prefix}/{best_resids_npy_folder}/{run_id}_best_resids_R2_{holdout_score_rnd}.csv', index=True, header=True)\n",
    "\n",
    "                        dfrel_basis[y_col + '_resid'] = (dfrel_basis[y_col] - dfrel['pred']).values\n",
    "                        if fix_training:\n",
    "                            dfrel_ft[y_col + '_resid'] = (dfrel_ft[y_col] - dfrel['pred']).values\n",
    "                            dfrel_ft_setup[y_col + '_resid'] = (dfrel_ft_setup[y_col] - dfrel_setup['pred']).values\n",
    "                            dfrel_ft_holdout[y_col + '_resid'] = (dfrel_ft_holdout[y_col] - dfrel_holdout['pred']).values\n",
    "\n",
    "                        # print(dfrel_resids)\n",
    "                        # print(dfrel[['pred']])\n",
    "                        # dfrel.set_index(['file_num_inx'], append=True, inplace=True)\n",
    "\n",
    "                        pred_col_name = f'pred_paramsNum={iXyd}_{y_col}_run_num={irun}' if num_runs > 1 else f'pred_paramsNum={iXyd}_{y_col}'\n",
    "\n",
    "                        dfrel_resids[pred_col_name] = glm.predict(dfrel_basis[prediction_X_cols_sftd])\n",
    "\n",
    "                        if len(dfrel_resids_setup):\n",
    "                            dfrel_resids_setup[pred_col_name] = glm.predict(dfrel_ft_setup[prediction_X_cols_sftd])\n",
    "                        if len(dfrel_resids_holdout):\n",
    "                            dfrel_resids_holdout[pred_col_name] = glm.predict(dfrel_ft_holdout[prediction_X_cols_sftd])\n",
    "\n",
    "\n",
    "                        # for fitted_model_dict in (cv_results['full_cv_results']):\n",
    "                        #     fitted_model = fitted_model_dict['model']\n",
    "                        #     kwarg_info = \"_\".join([f\"{_k}_{fitted_model_dict['glm_kwargs'][_k]}\" for _k in fitted_model_dict[\"glm_kwargs\"]])\n",
    "\n",
    "                        #     model_coef = fitted_model.coef_\n",
    "                        #     model_intercept = fitted_model.intercept_\n",
    "\n",
    "                        #     std_name = f'{run_id}_{kwarg_info}'\n",
    "                        #     np.save(f'{base_folder}/{prefix}/{all_models_folder}/coeffs/{std_name}_{model_c_basename}.npy', model_coef)\n",
    "                        #     np.save(f'{base_folder}/{prefix}/{all_models_folder}/intercepts/{std_name}_{model_i_basename}.npy', model_intercept)\n",
    "\n",
    "                        #     tmp_holdout_score = fitted_model.r2_score(X_holdout_noiti, y_holdout_noiti)\n",
    "                        #     holdout_score_rnd = np.round(tmp_holdout_score, 4)\n",
    "\n",
    "\n",
    "                        #     visualize.plot_all_beta_coefs(fitted_model.coef_, X_cols_plot,\n",
    "                        #                                     X_cols_sftd_plot,\n",
    "                        #                                     plot_width=4,\n",
    "                        #                                     y_lims=(-3.0, 3.0),\n",
    "                        #                                     # filename=f'{fn}_coeffs.png',\n",
    "                        #                                     binsize=54,\n",
    "                        #                                     filename=f'{base_folder}/{prefix}/{all_coeffs_folder}/{std_name}_{all_betas_basename}_R2_{holdout_score_rnd}.png',\n",
    "                        #                                     plot_name=f'Coeffs by Timeshift - {run_id}  {kwarg_info}'\n",
    "                        #                                     # plot_name=f'{fn}  {y_col}  {kwarg_info}'\n",
    "                        #                                     )\n",
    "\n",
    "\n",
    "                        #     visualize.plot_avg_reconstructions_v2(dfrel_holdout,\n",
    "                        #     # visualize.plot_avg_reconstructions_v2(dfrel,\n",
    "                        #                                     channel=y_col,\n",
    "                        #                                     plot_width=4,\n",
    "                        #                                     binsize = 54,\n",
    "                        #                                     min_time = -20,\n",
    "                        #                                     max_time = 30,\n",
    "                        #                                     min_signal = -2.5,\n",
    "                        #                                     max_signal = 2.5,\n",
    "                        #                                     file_name=f'{base_folder}/{prefix}/{all_reconstruct_folder}/{std_name}_{avg_reconstruct_basename}_R2_{holdout_score_rnd}.png',\n",
    "                        #                                     title=f'Average Reconstruction - {run_id}  {kwarg_info}'\n",
    "                        #                                 )\n",
    "\n",
    "                    if len(dfrel_resids) != 0 and holdout_score_rnd is not None:\n",
    "                        # dfrel_resids.set_index(['nTrial'], append=True, inplace=True)\n",
    "                        # dfrel_resids.to_csv(f'{base_folder}/{prefix}/{best_resids_npy_folder}/{fn}_best_resids_R2_{holdout_score_rnd}_all.csv', index=True, header=True)\n",
    "                        dfrel_resids.set_index(['nTrial_filenum'], append=True).to_csv(f'{base_folder}/{prefix}/{best_resids_npy_folder}/{fn}_best_resids_R2_{holdout_score_rnd}_all.csv', index=True, header=True)                \n",
    "                    if len(dfrel_resids_setup) != 0 and holdout_score_rnd is not None:\n",
    "                        # dfrel_resids_setup.set_index(['nTrial'], append=True, inplace=True)\n",
    "                        # dfrel_resids_setup.to_csv(f'{base_folder}/{prefix}/{best_resids_npy_folder}/{fn}_best_resids_R2_{holdout_score_rnd}_stp.csv', index=True, header=True)\n",
    "                        dfrel_resids_setup.set_index(['nTrial_filenum'], append=True).to_csv(f'{base_folder}/{prefix}/{best_resids_npy_folder}/{fn}_best_resids_R2_{holdout_score_rnd}_stp.csv', index=True, header=True)\n",
    "                    if len(dfrel_resids_holdout) != 0 and holdout_score_rnd is not None:\n",
    "                        # dfrel_resids_holdout.set_index(['nTrial'], append=True, inplace=True)\n",
    "                        # dfrel_resids_holdout.to_csv(f'{base_folder}/{prefix}/{best_resids_npy_folder}/{fn}_best_resids_R2_{holdout_score_rnd}_ho.csv', index=True, header=True)\n",
    "                        dfrel_resids_holdout.set_index(['nTrial_filenum'], append=True).to_csv(f'{base_folder}/{prefix}/{best_resids_npy_folder}/{fn}_best_resids_R2_{holdout_score_rnd}_ho.csv', index=True, header=True)\n",
    "\n",
    "        combined_best_coeffs = pd.concat(all_coeff_dfs, axis=0)\n",
    "        combined_best_coeffs.to_csv(f'{base_folder}/{prefix}/{best_combined_coeffs_folder}/best_coeffs_combo.csv', index=True, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[_ for _ in dfrel_ft.columns if _ not in dfrel.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fa0fc083a9a7b25dab36cbe71fb89b2f1907d4eced1698b208dea6977346b521"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "248.844px",
    "left": "1167px",
    "right": "20px",
    "top": "120px",
    "width": "504px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
